
library(data.table)
library(lightgbm)
library(Hmisc)
library(dplyr)
library(BBmisc)

#mltrain.df <- fread('../input/train.csv')

#Read Training Data
mltrain.df <- fread('train.csv')

#Check Size of the object
print(object.size(mltrain.df), units='auto')

#Shape of the dataframe
shape = as.array(dim(mltrain.df))

#Find columns with highest missing Values in percent
sort((colSums(is.na(mltrain.df))/shape[1])*100, decreasing=TRUE)

remove(shape)

#Remvoing column with more than 90% missing values and Machine identifier which plays no role in modeling
mltrain.df <- mltrain.df[,-c('DefaultBrowsersIdentifier','MachineIdentifier')]

# sapply(mltrain.df, class)

#Fitering only numeric columns
library(microbenchmark)
numcols<-Filter(is.numeric,mltrain.df)


#Create empty dataframe to check the distinct value of each numeric column
x= data.frame("Variable" = character(), 'Distinct' = integer(), stringsAsFactors = FALSE)

#Convert from Data table to dataframe {named column index doesnt work in data table}
mltrain.df<-as.data.frame(mltrain.df)
numcols<-as.data.frame(numcols)

#Fill Empty data frame
for (k in 1:52)
{
  x[k,1]<-names(numcols[k])
  x[k,2]<-length(unique(numcols[,k]))
}



#Columns with less than 5 unique values
z=x$Variable[x$Distinct<5]

#Print if these columns are skewed towards one value
library(formattable)

for (i in z)
{
  print(i)
  print(format(round(prop.table(table(numcols[,i]))*100),2))
  print('-------------------\n')
  print('-------------------\n')
}

#Following columns are 100% skewed values and therefore play no role in Modelling
#IsBeta, AutoSampleOptIn, SMode, Census_IsPortableOperatingSystem, Census_ISFlightingInternal, Census_IsFlightsDisabled,
#Census_ThresholdOptIn, Census_IsWIMBootEnabled 

remove(numcols)

#Remove skewed numeric columns
mltrain.df<-subset(mltrain.df, select = -c(IsBeta, AutoSampleOptIn,SMode,Census_IsPortableOperatingSystem,Census_IsFlightingInternal,Census_IsFlightsDisabled,Census_ThresholdOptIn,Census_IsWIMBootEnabled))

#Filter only character columns
charcols <- Filter(is.character,mltrain.df)

#Create empty dataframe to check the distinct value of each numeric column
x= data.frame("Variable" = character(), 'Distinct' = integer(), stringsAsFactors = FALSE)

#Convert from Data table to dataframe {named column index doesnt work in data table}
charcols<-as.data.frame(charcols)

for (k in 1:29)
{    
  x[k,1]<-names(charcols[k])
  x[k,2]<-length(unique(charcols[,k]))
}

z=x$Variable[x$Distinct<=5]
#Print if these columns are skewed towards one value
for (i in z)
{
  print(i)
  print(format(round(prop.table(table(charcols[,i]))*100),2))
  print('-------------------\n')
  print('-------------------\n')
}

#Remove skewed character columns
mltrain.df<-subset(mltrain.df, select = -c(PuaMode,Census_ProcessorClass,Census_DeviceFamily))

#Check reduced size of dataset
print(object.size(mltrain.df), units='auto')

remove(x)
remove(i)
remove(k)
remove(z)


numcols<-Filter(is.numeric,mltrain.df)
charcols <- Filter(is.character,mltrain.df)



#Find numerical columns with highest missing Values in percent
sort((colSums(is.na(numcols))/shape[1])*100, decreasing=TRUE)

#Mode Function for imputation
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#Na Values Imputation
numcols$OrganizationIdentifier[is.na(numcols$OrganizationIdentifier)]=Mode(numcols$OrganizationIdentifier)

numcols$CityIdentifier[is.na(numcols$CityIdentifier)]=Mode(numcols$CityIdentifier)

numcols$Wdft_RegionIdentifier[is.na(numcols$Wdft_RegionIdentifier)]=Mode(numcols$Wdft_RegionIdentifier)

numcols$Census_InternalBatteryNumberOfCharges[is.na(numcols$Census_InternalBatteryNumberOfCharges)]=Mode(numcols$Census_InternalBatteryNumberOfCharges)

#Check How many Na Values in Charnumcols
shape = as.array(dim(charcols))
sort((colSums(is.na(charcols))/shape[1])*100, decreasing=TRUE)


#Convert Character columns to Factors
charcols[sapply(charcols, is.character)] <- lapply(charcols[sapply(charcols, is.character)], as.factor)

#Convert Factor Columns to numeric
charnumcols <- charcols %>% mutate_if(is.factor, as.numeric)


remove(charcols)

train <- cbind(charnumcols,numcols)



mltrain <- na.omit(train)

remove(train)
#Size check
print(object.size(mltrain), units='auto')


#Feature engineering to find out highly correlated columns
library(tidyr)
library(tibble)

cormat <- mltrain %>% as.matrix %>% cor %>% abs %>% as.data.frame %>% rownames_to_column(var = 'var1') %>% gather(var2, value, -var1) 

corrmat<-cormat[order(-cormat$value),]

remove(cormat)

dfcor<-corrmat[which(corrmat$value>0.9),]

#--------------------------------------------------------------------------------------------------------
#HeatMap
library(corrplot)
library(ggplot2)
library(gplots)
heatmap.2(cor(mltrain), Rowv = FALSE, Colv = FALSE, dendrogram = "none", 
          cellnote = round(cor(mltrain),2), notecol = "black", key = FALSE, trace = 'none', margins = c(10,10))


#dfcor <- cormat[which(cormat$value>50),]

remove(cormat)
remove(dfcor)
head(cormat)

print(object.size(numcols), units='auto')

print(object.size(charcols), units='auto')

