library(data.table)
library(lightgbm)
library(Hmisc)
library(dplyr)
library(tidyr)
library(BBmisc)
library(gridExtra)
library(bit64)
library(tinytex)
library(rmarkdown)

#mltrain.df <- fread('../input/train.csv')


#Read Training Data
mltrain.df <- fread('train.csv',na.strings = c("","NA"))

#Shape of the dataframe
shape = as.array(dim(mltrain.df))
shape

#Check the size of dataset.
print(object.size(mltrain.df), units='auto')

memory.limit()

#Increase memory allocation for R
memory.limit(70384)

missing_df = mltrain.df %>%
  summarise_all(funs(sum(is.na(.)) / nrow(mltrain.df) * 100)) %>%
  gather(var, missing_pctg) 

missing_df %>%
  filter(missing_pctg > 0) %>%
  ggplot(aes(x = reorder(var, missing_pctg), y = missing_pctg, fill="Blue")) +
  geom_col() +
  xlab("")+
  ylab("")+
  labs(fill="")+
  theme(legend.position = "none")+
  geom_text(aes(label = paste0(round(missing_pctg,1), "%")), hjust = -0.1) +
  coord_flip(ylim = c(0, 105)) +
  labs(title = "Columns with missing rows")

remove(missing_df)

#Remvoing column with more than 90% missing values and Machine identifier which plays no role in modeling
mltrain.df <- mltrain.df[,-c('DefaultBrowsersIdentifier','MachineIdentifier', 'PuaMode', 'Census_ProcessorClass')]


#Fitering only numeric columns
library(microbenchmark)
numcols<-Filter(is.numeric,mltrain.df)


#Create empty dataframe to check the distinct value of each numeric column
x= data.frame("Variable" = character(), 'Distinct' = integer(), stringsAsFactors = FALSE)

#Convert from Data table to dataframe {named column index doesnt work in data table}
mltrain.df<-as.data.frame(mltrain.df)
numcols<-as.data.frame(numcols)

#Fill Empty data frame
for (k in 1:52)
{
  x[k,1]<-names(numcols[k])
  x[k,2]<-length(unique(numcols[,k]))
}


#Columns with less than 5 unique values
z=x$Variable[x$Distinct<5]

#Print if these columns are skewed towards one value
library(formattable)

for (i in z)
{
  print(i)
  print(format(round(prop.table(table(numcols[,i]))*100),2))
  print('-------------------\n')
}

#Following columns are 100% skewed values and therefore play no role in Modelling
#IsBeta, AutoSampleOptIn, SMode, Census_IsPortableOperatingSystem, Census_ISFlightingInternal, Census_IsFlightsDisabled,
#Census_ThresholdOptIn, Census_IsWIMBootEnabled 

remove(numcols)
remove(i)
remove(k)
remove(z)

#Remove skewed numeric columns
mltrain.df<-subset(mltrain.df, select = -c(IsBeta, AutoSampleOptIn,SMode,Census_IsPortableOperatingSystem,Census_IsFlightingInternal,Census_IsFlightsDisabled,Census_ThresholdOptIn,Census_IsWIMBootEnabled))

#Filter only character columns
charcols <- Filter(is.character,mltrain.df)

#Create empty dataframe to check the distinct value of each numeric column
x= data.frame("Variable" = character(), 'Distinct' = integer(), stringsAsFactors = FALSE)

#Convert from Data table to dataframe {named column index doesnt work in data table}
charcols<-as.data.frame(charcols)

for (k in 1:27)
{    
  x[k,1]<-names(charcols[k])
  x[k,2]<-length(unique(charcols[,k]))
}


z=x$Variable[x$Distinct<=5]



#Print if these columns are skewed towards one value
for (i in z)
{
  print(i)
  print(format(round(prop.table(table(charcols[,i]))*100),2))
  print('-------------------\n')
}

#Remove skewed character columns
mltrain.df<-subset(mltrain.df, select = -c(Census_DeviceFamily))

remove(x)
remove(i)
remove(k)
remove(z)
remove(charcols)

#Shape of the dataframe
shape = as.array(dim(mltrain.df))

#Find columns with highest missing Values in percent
miss<-(sort((colSums(is.na(mltrain.df))/shape[1])*100, decreasing=TRUE))
miss<-data.frame(dimnames(as.array(miss[miss>0])))

miss$c..Census_InternalBatteryType....SmartScreen....OrganizationIdentifier...<-as.character(miss$c..Census_InternalBatteryType....SmartScreen....OrganizationIdentifier...)


#Mode Function for imputation
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#Mode Function when mode of variable is Null
Modena<-function(x){
  ux <- unique(na.omit(x))
  ux[which.max(tabulate(match(x, ux)))]
}

#Na Value Imputations
for (i in 1:nrow(miss)) 
{
  if (is.na(Mode(mltrain.df[,miss[i,1]]))) 
  {
    mltrain.df[,miss[i,1]][is.na(mltrain.df[,miss[i,1]])] <- Modena(mltrain.df[,miss[i,1]])
    
  }
  else
  {
    mltrain.df[,miss[i,1]][is.na(mltrain.df[,miss[i,1]])]<-Mode(mltrain.df[,miss[i,1]])
  }
}

remove(miss)

numcols<-Filter(is.numeric,mltrain.df)
charcols <- Filter(is.character,mltrain.df)


#Convert Character columns to Factors
charcols[sapply(charcols, is.character)] <- lapply(charcols[sapply(charcols, is.character)], as.factor)

#Convert Factor Columns to numeric
charnumcols <- charcols %>% mutate_if(is.factor, as.numeric)


remove(charcols)

#Dataframe to calculate correlation
train <- cbind(charnumcols,numcols)

remove(numcols)
remove(charnumcols)

#find out highly correlated columns and eventually remove one from the pair having more than 99% correlation
library(tidyr)
library(tibble)

cormat <- train %>% as.matrix %>% cor %>% abs %>% as.data.frame %>% rownames_to_column(var = 'var1') %>% gather(var2, value, -var1) 

corrmat<-cormat[order(-cormat$value),]

remove(cormat)
#remove(train)

#More than 90 correlation
dfcor<-corrmat[which(corrmat$value>0.95),]
remove(corrmat)

#Approximately 100% Correlated pairs
#(OsVer-Platform),(Census_OSSkuName-Census_OSEdition), (Census_OSArchitecture-Processor)

mltrain.df<-subset(mltrain.df, select = -c(Platform, Census_OSEdition, Processor))
remove(dfcor)
train<- subset(train, select = -c(Platform, Census_OSEdition, Processor))

#Print reduced dataset Size
print(object.size(mltrain.df), units='auto')

remove(i)
remove(shape)
remove(Mode)
remove(Modena)
gc()

library(ggplot2)
library(corrplot)
library(gplots)
library(gridExtra)
library(grid)
library(ggpubr)

cormat <- train %>% as.matrix %>% cor %>% as.data.frame %>% rownames_to_column(var = 'var1') %>% gather(var2, value, -var1) 

cormat<-cormat[order(-cormat$value),]

#Data frame for correlation of all variables with HasDetection(Target Variable)
mat1<- cormat[which(cormat$var2=='HasDetections' & cormat$var1!='HasDetections'),]

remove(cormat)
remove(train)

mat1$value<-mat1$value*100

ggplot(mat1, aes(x = mat1$var2, y = mat1$var1)) + geom_tile(aes(fill = mat1$value),color='white', size=0.25)+scale_fill_gradient2(name = "Correlation", low = "forestgreen", mid="grey90", high = "firebrick1")+
  geom_text(aes(label=round(mat1$value,2)), size=2.5)+
  ggtitle("Heatmap for Correlation")+
  #theme(axis.text.y = element_text(angle = 10, hjust = 1))+
  theme(plot.title = element_text(lineheight=2, face="bold", size = 20, hjust = 0.5))+
  xlab("")+
  ylab("")+
  theme_grey(base_size=8)

mat1<-vector()

for (i in colnames(mltrain.df)) 
{
  if (length(unique(mltrain.df[,i]))<11) 
  {
    mat1<-append(mat1,i)
    
  }
  
}

#Create new data frame with variables having less than 11 unique factors
dt <- data.frame(mltrain.df[,mat1])

set.seed(0)

# dt = dt %>%
#   sample_n(nrow(dt))

remove(mat1)

character_cols = dt %>%
  select_if(function(x) !is.numeric(x)) %>%
  colnames()

identifier_cols = dt %>%
  select(matches("Identifier", ignore.case = F)) %>%
  colnames()

binary_cols = dt %>%
  select(matches("Is|Has", ignore.case = F)) %>%
  colnames()

binary_cols<-append(binary_cols,"Firewall")

#Plot HasDetection distribution in binary columns. 
lapply(binary_cols, function(col){
  dt %>%
    group_by(HasDetections, !!sym(col)) %>%
    count() %>%
    mutate(n_pctg = n/nrow(dt) * 100) %>%
    ggplot(aes(x = reorder(!!sym(col), -n_pctg), y = n_pctg, fill = HasDetections)) +
    geom_col(position = "fill") +
    scale_fill_gradient(name = "Detected", low = "forestgreen",high = "firebrick")+
    geom_text(aes(label = paste0(round(n_pctg, 2), "%")), size = 3, position = position_fill(vjust = 0.5)) +
    #geom_hline(yintercept = 0.5) +
    ylab("Proportion of Occurence") +
    theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust = 1)) +
    labs(title = col
         , x = col)
}) %>% 
  marrangeGrob(nrow=2, ncol = 1)
lapply(c(character_cols, identifier_cols), function(col){
  dt %>%
    group_by(HasDetections, !!sym(col)) %>%
    count() %>%
    mutate(n_pctg = n/nrow(dt) * 100) %>%
    ggplot(aes(x = reorder(!!sym(col), -n_pctg), y = n_pctg, fill = HasDetections)) +
    geom_col(position = "fill") +
    scale_fill_gradient(name = "Detected", low = "forestgreen",high = "firebrick")+
    geom_text(aes(label = paste0(round(n_pctg, 2), "%")), size = 3, position = position_fill(vjust = 0.5)) +
    ylab("Proportion of Occurence") +
    theme(axis.text.x = element_text(angle = 20, vjust = 1, hjust = 1)) +
    labs(title = col
         , x = col)
}) %>%
  marrangeGrob(nrow = 2, ncol = 1)

remove(binary_cols,character_cols,i,identifier_cols,mat1)
gc()



library(caret)
train.index <- createDataPartition(mltrain.df$HasDetections, p=0.65, list=FALSE)
train.df<-mltrain.df[train.index,]
valid.df<-mltrain.df[-train.index,]

rm(mltrain.df, train.index,dt)


#assign target variable to y_train
y_train <- mltrain.df$HasDetections
mltrain.df[, HasDetections := NULL]


#Check Size of the object
print(object.size(mltrain.df), units='auto')

numcols<-Filter(is.numeric,train.df)
charcols<-Filter(is.character,train.df)

#Convert Character columns to Factors
charcols[sapply(charcols, is.character)] <- lapply(charcols[sapply(charcols, is.character)], as.factor)

#Convert Factor Columns to numeric
charnumcols <- charcols %>% mutate_if(is.factor, as.numeric)


remove(charcols)

mltrain.df <- cbind(charnumcols,numcols)



#Size check
print(object.size(mltrain), units='auto')

#Read Test Data
mltest.df <- fread('test.csv')

# assign test data ids to id_test
id_test <- mltest.df$MachineIdentifier
mltest.df[, MachineIdentifier := NULL]

#Drop the same columns in Test
mltest.df <- mltest.df[,-c('DefaultBrowsersIdentifier','PuaMode','Census_ProcessorClass','Census_IsWIMBootEnabled','IsBeta','Census_IsFlightsDisabled','Census_IsFlightingInternal','AutoSampleOptIn','Census_ThresholdOptIn','SMode','Census_IsPortableOperatingSystem','Census_DeviceFamily','UacLuaenable','Census_IsVirtualDevice','Platform','Census_OSSkuName','Census_OSInstallLanguageIdentifier','Processor')]

gc()

#Test Data Pre Process
numcols<-Filter(is.numeric,mltest.df)
charcols <- Filter(is.character,mltest.df)

rm(mltest.df)

#Mode Function for imputation
Mode <- function(x) {unique(x[which.max(tabulate(match(x, x)))])}

#Na Values Imputation
numcols$OrganizationIdentifier[is.na(numcols$OrganizationIdentifier)]=Mode(numcols$OrganizationIdentifier)



numcols$Wdft_RegionIdentifier[is.na(numcols$Wdft_RegionIdentifier)] <- Mode(numcols$Wdft_RegionIdentifier)

numcols$Census_InternalBatteryNumberOfCharges[is.na(numcols$Census_InternalBatteryNumberOfCharges)]=Mode(numcols$Census_InternalBatteryNumberOfCharges)




#Convert Character columns to Factors
charcols <- charcols %>% mutate_if(is.character,as.factor)

#Convert Factor Columns to numeric
charnumcols <- charcols %>% mutate_if(is.factor, as.numeric)

mltest.df <- cbind(charnumcols,numcols)

rm(charnumcols)
rm(numcols)
rm(charcols)

gc()

# Set up processed data for lgbm
x_train <- lgb.Dataset(data = data.matrix(mltrain.df), label = y_train)



rm(mltrain.df); gc();


params = list(
  boosting_type = 'gbdt', 
  objective = 'binary',
  metric = 'auc', 
  nthread = 4, 
  learning_rate = 0.05, 
  max_depth = 5,
  num_leaves = 40,
  sub_feature = 0.1*9, 
  sub_row = 0.1*9, 
  bagging_freq = 1,
  lambda_l1 = 0.1, 
  lambda_l2 = 0.1
)



# train model
mod <- lgb.train(params = params,
                 nrounds = 5120,
                 data = x_train, 
                 verbose = 1
)

rm(X_train)
gc()

x_test <- data.matrix(mltest.df)

#predictions
preds <- predict(mod, data = x_test)

rm(x_test)

#submission
sub <- data.table(
  MachineIdentifier = id_test,
  HasDetections = preds
)
  
# write to disk
fwrite(sub, file ='submission_Rajgor_LGBM.csv', row.names = FALSE)
rm(params, lgbm_mod, preds, sub)
gc()
